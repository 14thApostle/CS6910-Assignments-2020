{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "test_dir = \"/home/lordgrim/Work/Courses/CS6910/A1/5/test/\"\n",
    "img_h,img_w = 84,84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
    "        self.conv1a = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv2a = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
    "        self.conv3a = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=33)      # change out_features according to number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv1a(x)))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(self.conv2a(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(self.conv3a(x))\n",
    "\n",
    "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "path_model = \"/home/lordgrim/Work/Courses/CS6910/A1/models/62_nice.pth\"\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# transfer the model to GPU\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    \n",
    "net.load_state_dict(torch.load(path_model))\n",
    "summary(net.cuda(),(3,img_h,img_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "def image_loader(image):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image)\n",
    "    np_img = np.array(image)\n",
    "    image = loader(image).float()\n",
    "    return image.cuda(), np_img  #assumes that you're using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## For layer 1\n",
    "max_act = {0:[],1:[],2:[]}\n",
    "\n",
    "img_patch_all = {0:[],1:[],2:[]}\n",
    "\n",
    "for class_label in os.listdir(test_dir):\n",
    "    print(class_label)\n",
    "    for img_path in os.listdir(test_dir + class_label):\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        net.conv1.register_forward_hook(get_activation('conv1'))\n",
    "        inp, img = image_loader(test_dir+class_label+\"/\"+img_path)\n",
    "\n",
    "        out = net(torch.reshape(inp, (-1, 3, img_h, img_w) ))\n",
    "        act = activation['conv1'].squeeze().cpu()\n",
    "\n",
    "        # Receptive field\n",
    "        # We are using square kernel only, so x=y\n",
    "        rc_field = net.conv1.kernel_size[0] \n",
    "\n",
    "        act_10= act[9,:,:] # 10nd filter\n",
    "        act_17 = act[16,:,:] # 6th filter\n",
    "        act_31 = act[30,:,:] #31st filter\n",
    "\n",
    "        for j,act_val in enumerate([act_10,act_17,act_31]):\n",
    "\n",
    "            ## To get the top5 max in the array, we need to flatten and then find\n",
    "            top5 = torch.topk(torch.flatten(act_val),5)\n",
    "            max_vals = top5[0]\n",
    "            ans = top5[1]\n",
    "\n",
    "            max_x = ans%act_val.shape[0]\n",
    "            max_y = ans//act_val.shape[1]\n",
    "\n",
    "            \n",
    "            \n",
    "            for i,(x,y) in enumerate(zip(max_x,max_y)):\n",
    "                \n",
    "                x, y = int(x.numpy()), int(y.numpy())\n",
    "\n",
    "                x1 = x \n",
    "                x2 = x + rc_field\n",
    "                y1 = y \n",
    "                y2 = y + rc_field\n",
    "\n",
    "\n",
    "                img_patch_d = [test_dir+class_label+\"/\"+img_path,(x1,x2,y1,y2)]\n",
    "\n",
    "                max_act[j].append(max_vals[i])\n",
    "                img_patch_all[j].append(img_patch_d)\n",
    "\n",
    "        # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,layer in enumerate(['layer_10','layer_17','layer_31']):\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    activations = np.array(max_act[j])\n",
    "    img_patches = img_patch_all[j]\n",
    "\n",
    "    temp = np.argpartition(-activations, 5)\n",
    "    result_args = temp[:5]\n",
    "    print(result_args)\n",
    "\n",
    "    f, axarr = plt.subplots(2,5, figsize=(15,15))\n",
    "    for i,index in enumerate(result_args):\n",
    "        vals = img_patches[index]\n",
    "        img = np.array(Image.open(vals[0]))\n",
    "        x1, x2, y1, y2 = vals[1]\n",
    "        img_patch = img[y1:y2,x1:x2]\n",
    "        # ax = fig.add_subplot(3, 5, 5*j + i + 1)\n",
    "\n",
    "        axarr[0,i].axis('off',aspect=\"auto\")\n",
    "        axarr[0,i].imshow(img)\n",
    "        axarr[1,i].axis('off',aspect=\"auto\")\n",
    "        axarr[1,i].imshow(img_patch)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    f.savefig('conv1_{}.png'.format(layer))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For 2nd conv layer\n",
    "max_act = {0:[],1:[],2:[]}\n",
    "\n",
    "img_patch_all = {0:[],1:[],2:[]}\n",
    "\n",
    "for class_label in os.listdir(test_dir):\n",
    "    print(class_label)\n",
    "    for img_path in os.listdir(test_dir + class_label):\n",
    "\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        net.conv1a.register_forward_hook(get_activation('conv1a'))\n",
    "        inp, img = image_loader(test_dir+class_label+\"/\"+img_path)\n",
    "\n",
    "        out = net(torch.reshape(inp, (-1, 3, img_h, img_w) ))\n",
    "        act = activation['conv1a'].squeeze().cpu()\n",
    "\n",
    "        # Receptive field\n",
    "        # We are using square kernel only, so x=y\n",
    "\n",
    "        act_1= act[18,:,:] # 10nd filter\n",
    "        act_2 = act[2,:,:] # 6th filter\n",
    "        act_3 = act[3,:,:] # 61th filter\n",
    "\n",
    "        for j,act_val in enumerate([act_1,act_2,act_3]):\n",
    "\n",
    "            ## To get the top5 max in the array, we need to flatten and then find\n",
    "            top5 = torch.topk(torch.flatten(act_val),5)\n",
    "            max_vals = top5[0]\n",
    "            ans = top5[1]\n",
    "\n",
    "            max_x = ans%act_val.shape[0]\n",
    "            max_y = ans//act_val.shape[1]\n",
    "\n",
    "            \n",
    "            \n",
    "            for i,(x,y) in enumerate(zip(max_x,max_y)):\n",
    "                \n",
    "                x, y = int(x.numpy()), int(y.numpy())\n",
    "\n",
    "                x1 = x \n",
    "                x2 = x+ 5\n",
    "                y1 = y \n",
    "                y2 = y+ 5\n",
    "\n",
    "\n",
    "                img_patch_d = [test_dir+class_label+\"/\"+img_path,(x1,x2,y1,y2)]\n",
    "\n",
    "                max_act[j].append(max_vals[i])\n",
    "                img_patch_all[j].append(img_patch_d)\n",
    "\n",
    "        # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,layer in enumerate(['layer_10','layer_6','layer_61']):\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    activations = np.array(max_act[j])\n",
    "    img_patches = img_patch_all[j]\n",
    "\n",
    "    temp = np.argpartition(-activations, 5)\n",
    "    result_args = temp[:5]\n",
    "    print(result_args)\n",
    "\n",
    "    f, axarr = plt.subplots(2,5, figsize=(15,15))\n",
    "    for i,index in enumerate(result_args):\n",
    "        vals = img_patches[index]\n",
    "        img = np.array(Image.open(vals[0]))\n",
    "        x1, x2, y1, y2 = vals[1]\n",
    "        img_patch = img[y1:y2,x1:x2]\n",
    "        # ax = fig.add_subplot(3, 5, 5*j + i + 1)\n",
    "\n",
    "        axarr[0,i].axis('off',aspect=\"auto\")\n",
    "        axarr[0,i].imshow(img)\n",
    "        axarr[1,i].axis('off',aspect=\"auto\")\n",
    "        axarr[1,i].imshow(img_patch)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    f.savefig('conv2_{}.png'.format(layer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For 3nd conv layer\n",
    "max_act = {0:[],1:[],2:[]}\n",
    "\n",
    "img_patch_all = {0:[],1:[],2:[]}\n",
    "\n",
    "for class_label in os.listdir(test_dir):\n",
    "    print(class_label)\n",
    "    for img_path in os.listdir(test_dir + class_label):\n",
    "\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        net.conv2.register_forward_hook(get_activation('conv2'))\n",
    "        inp, img = image_loader(test_dir+class_label+\"/\"+img_path)\n",
    "\n",
    "        out = net(torch.reshape(inp, (-1, 3, img_h, img_w) ))\n",
    "        act = activation['conv2'].squeeze().cpu()\n",
    "\n",
    "        # Receptive field\n",
    "        # We are using square kernel only, so x=y\n",
    "\n",
    "        act_1= act[6,:,:] # 10nd filter\n",
    "        act_2 = act[35,:,:] # 6th filter\n",
    "        act_3 = act[58,:,:] # 61th filter\n",
    "\n",
    "        for j,act_val in enumerate([act_1,act_2,act_3]):\n",
    "\n",
    "            ## To get the top5 max in the array, we need to flatten and then find\n",
    "            top5 = torch.topk(torch.flatten(act_val),5)\n",
    "            max_vals = top5[0]\n",
    "            ans = top5[1]\n",
    "\n",
    "            max_x = ans%act_val.shape[0]\n",
    "            max_y = ans//act_val.shape[1]\n",
    "\n",
    "            \n",
    "            \n",
    "            for i,(x,y) in enumerate(zip(max_x,max_y)):\n",
    "                \n",
    "                x, y = int(x.numpy()), int(y.numpy())\n",
    "\n",
    "                x1 = 2*x \n",
    "                x2 = 2*x + 11\n",
    "                y1 = 2*y \n",
    "                y2 = 2*y + 11\n",
    "\n",
    "\n",
    "                img_patch_d = [test_dir+class_label+\"/\"+img_path,(x1,x2,y1,y2)]\n",
    "\n",
    "                max_act[j].append(max_vals[i])\n",
    "                img_patch_all[j].append(img_patch_d)\n",
    "\n",
    "        # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,layer in enumerate(['layer_10','layer_6','layer_61']):\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    activations = np.array(max_act[j])\n",
    "    img_patches = img_patch_all[j]\n",
    "\n",
    "    temp = np.argpartition(-activations, 5)\n",
    "    result_args = temp[:5]\n",
    "    print(result_args)\n",
    "\n",
    "    f, axarr = plt.subplots(2,5, figsize=(15,15))\n",
    "    for i,index in enumerate(result_args):\n",
    "        vals = img_patches[index]\n",
    "        img = np.array(Image.open(vals[0]))\n",
    "        x1, x2, y1, y2 = vals[1]\n",
    "        img_patch = img[y1:y2,x1:x2]\n",
    "        # ax = fig.add_subplot(3, 5, 5*j + i + 1)\n",
    "\n",
    "        axarr[0,i].axis('off',aspect=\"auto\")\n",
    "        axarr[0,i].imshow(img)\n",
    "        axarr[1,i].axis('off',aspect=\"auto\")\n",
    "        axarr[1,i].imshow(img_patch)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    f.savefig('conv3_{}.png'.format(layer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For 4th conv layer\n",
    "max_act = {0:[],1:[],2:[]}\n",
    "\n",
    "img_patch_all = {0:[],1:[],2:[]}\n",
    "\n",
    "for class_label in os.listdir(test_dir):\n",
    "    print(class_label)\n",
    "    for img_path in os.listdir(test_dir + class_label):\n",
    "\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        net.conv2a.register_forward_hook(get_activation('conv2a'))\n",
    "        inp, img = image_loader(test_dir+class_label+\"/\"+img_path)\n",
    "\n",
    "        out = net(torch.reshape(inp, (-1, 3, img_h, img_w) ))\n",
    "        act = activation['conv2a'].squeeze().cpu()\n",
    "\n",
    "        # Receptive field\n",
    "        # We are using square kernel only, so x=y\n",
    "\n",
    "        act_1= act[3,:,:] # 10nd filter\n",
    "        act_2 = act[1,:,:] # 6th filter\n",
    "        act_3 = act[15,:,:] # 61th filter\n",
    "\n",
    "        for j,act_val in enumerate([act_1,act_2,act_3]):\n",
    "\n",
    "            ## To get the top5 max in the array, we need to flatten and then find\n",
    "            top5 = torch.topk(torch.flatten(act_val),5)\n",
    "            max_vals = top5[0]\n",
    "            ans = top5[1]\n",
    "\n",
    "            max_x = ans%act_val.shape[0]\n",
    "            max_y = ans//act_val.shape[1]\n",
    "\n",
    "            \n",
    "            \n",
    "            for i,(x,y) in enumerate(zip(max_x,max_y)):\n",
    "                \n",
    "                x, y = int(x.numpy()), int(y.numpy())\n",
    "\n",
    "                x1 = 2*x \n",
    "                x2 = 2*x + 15\n",
    "                y1 = 2*y \n",
    "                y2 = 2*y + 15\n",
    "\n",
    "\n",
    "                img_patch_d = [test_dir+class_label+\"/\"+img_path,(x1,x2,y1,y2)]\n",
    "\n",
    "                max_act[j].append(max_vals[i])\n",
    "                img_patch_all[j].append(img_patch_d)\n",
    "\n",
    "        # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,layer in enumerate(['layer_10','layer_6','layer_61']):\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    activations = np.array(max_act[j])\n",
    "    img_patches = img_patch_all[j]\n",
    "\n",
    "    temp = np.argpartition(-activations, 5)\n",
    "    result_args = temp[:5]\n",
    "    print(result_args)\n",
    "\n",
    "    f, axarr = plt.subplots(2,5, figsize=(15,15))\n",
    "    for i,index in enumerate(result_args):\n",
    "        vals = img_patches[index]\n",
    "        img = np.array(Image.open(vals[0]))\n",
    "        x1, x2, y1, y2 = vals[1]\n",
    "        img_patch = img[y1:y2,x1:x2]\n",
    "        # ax = fig.add_subplot(3, 5, 5*j + i + 1)\n",
    "\n",
    "        axarr[0,i].axis('off',aspect=\"auto\")\n",
    "        axarr[0,i].imshow(img)\n",
    "        axarr[1,i].axis('off',aspect=\"auto\")\n",
    "        axarr[1,i].imshow(img_patch)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    f.savefig('conv4_{}.png'.format(layer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## For 5th conv layer\n",
    "max_act = {0:[],1:[],2:[]}\n",
    "\n",
    "img_patch_all = {0:[],1:[],2:[]}\n",
    "\n",
    "for class_label in os.listdir(test_dir):\n",
    "    print(class_label)\n",
    "    for img_path in os.listdir(test_dir + class_label):\n",
    "\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "            return hook\n",
    "        net.conv3.register_forward_hook(get_activation('conv3'))\n",
    "        inp, img = image_loader(test_dir+class_label+\"/\"+img_path)\n",
    "\n",
    "        out = net(torch.reshape(inp, (-1, 3, img_h, img_w) ))\n",
    "        act = activation['conv3'].squeeze().cpu()\n",
    "        # print(act.shape)\n",
    "\n",
    "        # Receptive field\n",
    "        # We are using square kernel only, so x=y\n",
    "\n",
    "        act_1= act[200,:,:] # 10nd filter\n",
    "        act_2 = act[35,:,:] # 6th filter\n",
    "        act_3 = act[95,:,:] # 61th filter\n",
    "\n",
    "        for j,act_val in enumerate([act_1,act_2,act_3]):\n",
    "\n",
    "            ## To get the top5 max in the array, we need to flatten and then find\n",
    "            top5 = torch.topk(torch.flatten(act_val),5)\n",
    "            max_vals = top5[0]\n",
    "            ans = top5[1]\n",
    "\n",
    "            max_x = ans%act_val.shape[0]\n",
    "            max_y = ans//act_val.shape[1]\n",
    "\n",
    "            \n",
    "            \n",
    "            for i,(x,y) in enumerate(zip(max_x,max_y)):\n",
    "                \n",
    "                x, y = int(x.numpy()), int(y.numpy())\n",
    "\n",
    "                x1 = 4*x \n",
    "                x2 = 4*x + 25\n",
    "                y1 = 4*y \n",
    "                y2 = 4*y + 25\n",
    "\n",
    "\n",
    "                img_patch_d = [test_dir+class_label+\"/\"+img_path,(x1,x2,y1,y2)]\n",
    "\n",
    "                max_act[j].append(max_vals[i])\n",
    "                img_patch_all[j].append(img_patch_d)\n",
    "\n",
    "        # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,layer in enumerate(['layer_10','layer_6','layer_61']):\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    activations = np.array(max_act[j])\n",
    "    img_patches = img_patch_all[j]\n",
    "\n",
    "    temp = np.argpartition(-activations, 5)\n",
    "    result_args = temp[:5]\n",
    "    print(result_args)\n",
    "\n",
    "    f, axarr = plt.subplots(2,5, figsize=(15,15))\n",
    "    for i,index in enumerate(result_args):\n",
    "        vals = img_patches[index]\n",
    "        img = np.array(Image.open(vals[0]))\n",
    "        x1, x2, y1, y2 = vals[1]\n",
    "        img_patch = img[y1:y2,x1:x2]\n",
    "        print(x1, x2, y1, y2)\n",
    "        # ax = fig.add_subplot(3, 5, 5*j + i + 1)\n",
    "\n",
    "        axarr[0,i].axis('off',aspect=\"auto\")\n",
    "        axarr[0,i].imshow(img)\n",
    "        axarr[1,i].axis('off',aspect=\"auto\")\n",
    "        axarr[1,i].imshow(img_patch)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    f.savefig('conv5_{}.png'.format(layer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}